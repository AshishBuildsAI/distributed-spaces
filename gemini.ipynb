{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai \n",
    "import tqdm as notebook_tqdm\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "GOOGLE_API_KEY=\"AIzaSyCN6yPJ9TM44yDCkmyAXafMq6bO15jv3MI\"\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> As a language model, I can't provide a definitive answer to the question of the meaning of life. This is a philosophical question that has been pondered by humans for centuries, and there is no single, universally agreed upon answer. \n",
       "> \n",
       "> Here's why:\n",
       "> \n",
       "> * **It's a subjective question:** The meaning of life is personal and can vary greatly from person to person. \n",
       "> * **It's an ongoing journey:** Many people believe that the meaning of life is something we discover throughout our lives, not something we are given at birth.\n",
       "> * **It's influenced by various factors:** Our experiences, beliefs, values, and cultural background all contribute to our understanding of life's purpose.\n",
       "> \n",
       "> However, I can offer some perspectives that people have used to find meaning in their lives:\n",
       "> \n",
       "> * **Finding purpose:**  Some believe in finding a specific purpose or mission in life, whether it's contributing to society, pursuing a passion, or raising a family.\n",
       "> * **Experiencing joy and love:** Others focus on experiencing joy, love, and connection with others as the primary goal of life.\n",
       "> * **Self-discovery and growth:** Some prioritize personal growth, learning, and exploring the world around them.\n",
       "> * **Leaving a legacy:**  A common theme is the desire to leave a positive impact on the world and be remembered for something good.\n",
       "> \n",
       "> Ultimately, the meaning of life is a question you need to answer for yourself. It's a journey of exploration, discovery, and personal reflection.\n",
       "> \n",
       "> If you're interested in exploring this question further, I recommend reading works by philosophers like Viktor Frankl, Jean-Paul Sartre, and Albert Camus. You can also consider talking to friends, family members, or a spiritual advisor. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = language_model.generate_content(\"What is the meaning of life?\")\n",
    "to_markdown(response.text)\n",
    "#print(response.candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PORT 5432\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "print(\"PORT\", os.environ[\"PORT\"])\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"ai\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"127.0.0.1\",\n",
    "    port=5432\n",
    ")\n",
    "register_vector(conn)\n",
    "dbschema = \"public\"\n",
    "dbtable = \"spaces_eicp\"\n",
    "cur = conn.cursor()\n",
    "model_dir = \"models/all-MiniLM-L6-v2\"\n",
    "embedding_model =''\n",
    "language_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Check if the model directory exists\n",
    "if not os.path.exists(model_dir):\n",
    "    # Load and save the model to the specified directory\n",
    "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embedding_model.save(model_dir)\n",
    "else:\n",
    "    # Load the model from the specified directory\n",
    "    embedding_model = SentenceTransformer(model_dir)\n",
    "\n",
    "def get_embeddings(content):\n",
    "    # Generate embeddings using the local model\n",
    "    embeddings = embedding_model.encode(content, convert_to_tensor=True)\n",
    "    return embeddings.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 26.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document describes the \"Open Door Policy\" for handling issues and problems. ðŸ˜Š \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> The document describes the \"Open Door Policy\" for handling issues and problems. ðŸ˜Š \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from psycopg2.extras import execute_values\n",
    "from psycopg2.extras import execute_values\n",
    "def get_top1_similar_docs(query_embedding, conn, schema, table):\n",
    "    # Normalize the query embedding\n",
    "    query_embedding = np.array(query_embedding)\n",
    "    query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    # Use normalized embeddings and add additional filters for relevance\n",
    "    cur.execute(f\"\"\"\n",
    "        SELECT pageno, context, tabletext, source, imagepath, embedding, COALESCE(numtokens, 0)\n",
    "        FROM {schema}.{table}\n",
    "    \"\"\")\n",
    "    \n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    # Compute similarities and store results\n",
    "    results = []\n",
    "    for row in rows:\n",
    "        pageno, context, tabletext, source, imagepath, embedding, numtokens = row\n",
    "        embedding = np.array(embedding)\n",
    "        embedding = embedding / np.linalg.norm(embedding)\n",
    "        similarity = np.dot(query_embedding, embedding)\n",
    "        \n",
    "        # Ensure numtokens is a valid number\n",
    "        numtokens = numtokens if numtokens is not None else 0\n",
    "        \n",
    "        # Optionally, weight similarity by the number of tokens or other criteria\n",
    "        weighted_similarity = similarity * (1 + 0.01 * numtokens)\n",
    "        \n",
    "        results.append((pageno, context, tabletext, source, imagepath, weighted_similarity))\n",
    "    \n",
    "    # Sort results by weighted similarity\n",
    "    results.sort(key=lambda x: x[-1], reverse=True)\n",
    "    \n",
    "    # Return the top 3 most similar documents\n",
    "    top3_docs = results[:5]\n",
    "    return top3_docs\n",
    "\n",
    "question = \"How does one Handling Interpersonal Problems?\"\n",
    "embed = get_embeddings(question)\n",
    "res = get_top1_similar_docs(embed, conn=conn,schema=dbschema, table=dbtable)\n",
    "envelope=f\"You are an AI assitant, capable of replying with precise information only from the documetn or documents,if dont know the answer, dont answer from anywhere only use the context {res} to answer the question {question}, add smiley in the end\"\n",
    "response = language_model.generate_content(envelope)\n",
    "print(response.text)\n",
    "to_markdown(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
