{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish.Madkaikar\\OneDrive - Emerson\\Source\\ai_agents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 20:50:18,976 - micro - MainProcess - INFO     PDFHelper initialized. (pdf_data_extractor.py:__init__:20)\n"
     ]
    }
   ],
   "source": [
    "# Question about Timescale we want the model to answer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "#parent_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "parent_dir = os.path.dirname(os.path.realpath(os.path.abspath('..\\\\')))\n",
    "print(parent_dir)\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "from extractors.ocr_data_extractor import OCRHelper\n",
    "from ocr.transformer import GPT4VisionManager\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np \n",
    "import re\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extras import execute_batch, execute_values\n",
    "import openai\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import camelot\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'extractors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mextractors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mocr_data_extractor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OCRHelper\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytesseract\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'extractors'"
     ]
    }
   ],
   "source": [
    "from extractors.ocr_data_extractor import OCRHelper\n",
    "import pytesseract\n",
    "import cv2\n",
    "def extract_text_from_images_os_opencv(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Processes a single image file and extracts all text .\n",
    "        Args:\n",
    "            file_path (str): Path to the image file.\n",
    "            output_path (str): Directory where the images will be saved.\n",
    "        \"\"\"\n",
    "        with Image.open(file_path) as img:\n",
    "            # Perform OCR on the image using Tesseract\n",
    "            # Load image, grayscale, apply sharpening filter, Otsu's threshold \n",
    "            image = cv2.imread(file_path)\n",
    "            img = cv2.medianBlur(image,5)\n",
    "            ret,th1 = cv2.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "            th2 = cv2.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "                        cv2.THRESH_BINARY,11,2)\n",
    "            th3 = cv2.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                        cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "            sharpen = cv2.filter2D(gray, -1, sharpen_kernel)\n",
    "            thresh = cv2.threshold(sharpen, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            ocr_text = pytesseract.image_to_string(thresh)\n",
    "            return ocr_text\n",
    "\n",
    "OCRHelper = OCRHelper()\n",
    "pageno = 1\n",
    "working_directory = os.getcwd() + \"\\\\data\\\\\"\n",
    "inputfile = f\"valve.png\"\n",
    "file = f\"{working_directory}\\\\{inputfile}\"\n",
    "#text = OCRHelper.extract_text_from_images_os(file)\n",
    "text = OCRHelper.extract_text_from_images_os_opencv(file)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import extract_tables_from_pdf\n",
    "from ocr.transformer import GPT4VisionManager\n",
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "def run_gpt4v_image_fisher(inputfile, pageno):\n",
    "    gpt_vision_client = GPT4VisionManager()\n",
    "    gpt_vision_client.load_environment_variables_from_env_file()\n",
    "    pdf_images_path = inputfile.replace(\".pdf\",\"\")\n",
    "    working_directory = os.getcwd()\n",
    "    image_file_path = f\"{working_directory}\\\\tempimages\\\\{pdf_images_path}\\\\{pdf_images_path}-page-{pageno}.png\"\n",
    "\n",
    "    working_directory = os.getcwd() + \"\\\\data\\\\\"\n",
    "    file = f\"{working_directory}\\\\{inputfile}\"\n",
    "    tables = extract_tables_from_pdf(file, f\"{pageno}\",'stream')\n",
    "    #table_question = False\n",
    "    table_text = \"\"\n",
    "    try: \n",
    "        for table in tables:\n",
    "            table_text += table.df.to_string(index=False)        \n",
    "    except Exception as e:\n",
    "        table_text = \"No table found\"\n",
    "    \n",
    "    #table_text = parse_tables(inputfile, pageno, {})\n",
    "    \n",
    "    sys_message = \"'You are an AI assistant capable of processing and summarizing complex documents with diagrams.'\"\n",
    "    user_prompt = \"Please analyze this document ignoring information in tables and provide the information in the following format:\\\\r\\\\n1. Summary: Provide a concise summary of the document, focusing on the main points and overall context.\\\\r\\\\n2. Content: Your task is to extract all information from the document in a detailed and granular manner. Pay special attention to diagrams. Ensure that no information is omitted and no tables are summarized. Avoid summarizing; instead, be explicit with the details. Take your time, as the purpose is to thoroughly record all the information from the document.\\\\r\\\\n3. Category: List key categories or keywords, with a focus on main products or concepts mentioned in the document. Categories should be abstracted and listed, separated by commas, with a maximum of 10 words.\\\\r\\\\nThe purpose is to enable another system to read and understand this information in detail, to facilitate answering precise questions based on the document\\'s context.\\\\r\\\\nPlease return the information in the following format:\\\\r\\\\n\\\\r\\\\n#summary\\\\r\\\\n<summary text>\\\\r\\\\n\\\\r\\\\n#content\\\\r\\\\n<content text>\\\\r\\\\n\\\\r\\\\n#category\\\\r\\\\n[<category 1>, <category 2>, <category 3>, ...]\"\n",
    "\n",
    "    extracted_context = gpt_vision_client.call_gpt4v_image(\n",
    "        image_file_path,\n",
    "        system_instruction=sys_message,\n",
    "        user_instruction=user_prompt,\n",
    "        ocr=True,\n",
    "        use_vision_api=True,\n",
    "        display_image=False,\n",
    "        max_tokens=2000,\n",
    "        seed=42,\n",
    "    )\n",
    "    #time.sleep(61)\n",
    "    return extracted_context, table_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 12:15:14,672 - micro - MainProcess - INFO     Preparing instruction for GPT-4 Vision API call. (transformer.py:prepare_instruction:119)\n",
      "2024-03-14 12:15:14,674 - micro - MainProcess - INFO     Instruction: [{'role': 'system', 'content': [{'type': 'text', 'text': \"'You are an AI assistant capable of processing and summarizing complex documents with diagrams.'\"}]}, {'role': 'user', 'content': [{'type': 'text', 'text': \"Please analyze this document ignoring information in tables and provide the information in the following format:\\\\r\\\\n1. Summary: Provide a concise summary of the document, focusing on the main points and overall context.\\\\r\\\\n2. Content: Your task is to extract all information from the document in a detailed and granular manner. Pay special attention to diagrams. Ensure that no information is omitted and no tables are summarized. Avoid summarizing; instead, be explicit with the details. Take your time, as the purpose is to thoroughly record all the information from the document.\\\\r\\\\n3. Category: List key categories or keywords, with a focus on main products or concepts mentioned in the document. Categories should be abstracted and listed, separated by commas, with a maximum of 10 words.\\\\r\\\\nThe purpose is to enable another system to read and understand this information in detail, to facilitate answering precise questions based on the document's context.\\\\r\\\\nPlease return the information in the following format:\\\\r\\\\n\\\\r\\\\n#summary\\\\r\\\\n<summary text>\\\\r\\\\n\\\\r\\\\n#content\\\\r\\\\n<content text>\\\\r\\\\n\\\\r\\\\n#category\\\\r\\\\n[<category 1>, <category 2>, <category 3>, ...]\"}]}] (transformer.py:prepare_instruction:123)\n",
      "2024-03-14 12:15:14,674 - micro - MainProcess - INFO     Image URL added to user message successfully. (transformer.py:add_image_url_to_user_message:163)\n",
      "2024-03-14 12:15:14,675 - micro - MainProcess - INFO     Sending request to https://az-openai-autosol-genai-n-001.openai.azure.com/openai/deployments/gpt-4-vision/extensions/chat/completions?api-version=2023-07-01-preview (transformer.py:call_gpt4v_image:247)\n",
      "2024-03-14 12:15:17,585 - micro - MainProcess - ERROR    Failed to make the request. Error: 429 Client Error: Too Many Requests for url: https://az-openai-autosol-genai-n-001.openai.azure.com/openai/deployments/gpt-4-vision/extensions/chat/completions?api-version=2023-07-01-preview (transformer.py:call_gpt4v_image:298)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive - Emerson\\Source\\ai_agents\\ocr\\transformer.py:288\u001b[0m, in \u001b[0;36mGPT4VisionManager.call_gpt4v_image\u001b[1;34m(self, image_file_path, system_instruction, user_instruction, ocr, grounding, in_context, use_vision_api, temperature, top_p, max_tokens, seed, model_version, display_image)\u001b[0m\n\u001b[0;32m    287\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(api_url, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[1;32m--> 288\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest successful.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\iitm\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://az-openai-autosol-genai-n-001.openai.azure.com/openai/deployments/gpt-4-vision/extensions/chat/completions?api-version=2023-07-01-preview",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m option \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstruction-manual-fisher-et-eat-easy-e-valves-cl125-through-cl600-en-124782.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m extracted_context, table_text \u001b[38;5;241m=\u001b[39m \u001b[43mrun_gpt4v_image_fisher\u001b[49m\u001b[43m(\u001b[49m\u001b[43moption\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpageno\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#print(extracted_context, table_text)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m, in \u001b[0;36mrun_gpt4v_image_fisher\u001b[1;34m(inputfile, pageno)\u001b[0m\n\u001b[0;32m     27\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease analyze this document ignoring information in tables and provide the information in the following format:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn1. Summary: Provide a concise summary of the document, focusing on the main points and overall context.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn2. Content: Your task is to extract all information from the document in a detailed and granular manner. Pay special attention to diagrams. Ensure that no information is omitted and no tables are summarized. Avoid summarizing; instead, be explicit with the details. Take your time, as the purpose is to thoroughly record all the information from the document.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn3. Category: List key categories or keywords, with a focus on main products or concepts mentioned in the document. Categories should be abstracted and listed, separated by commas, with a maximum of 10 words.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnThe purpose is to enable another system to read and understand this information in detail, to facilitate answering precise questions based on the document\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms context.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnPlease return the information in the following format:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn#summary\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn<summary text>\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn#content\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn<content text>\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn#category\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn[<category 1>, <category 2>, <category 3>, ...]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 29\u001b[0m extracted_context \u001b[38;5;241m=\u001b[39m \u001b[43mgpt_vision_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_gpt4v_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mocr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_vision_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m61\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive - Emerson\\Source\\ai_agents\\ocr\\transformer.py:299\u001b[0m, in \u001b[0;36mGPT4VisionManager.call_gpt4v_image\u001b[1;34m(self, image_file_path, system_instruction, user_instruction, ocr, grounding, in_context, use_vision_api, temperature, top_p, max_tokens, seed, model_version, display_image)\u001b[0m\n\u001b[0;32m    298\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to make the request. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 299\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to make the request. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mSystemExit\u001b[0m: Failed to make the request. Error: 429 Client Error: Too Many Requests for url: https://az-openai-autosol-genai-n-001.openai.azure.com/openai/deployments/gpt-4-vision/extensions/chat/completions?api-version=2023-07-01-preview",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\iitm\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\iitm\\lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\iitm\\lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\iitm\\lib\\site-packages\\IPython\\core\\ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\iitm\\lib\\site-packages\\IPython\\core\\ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\iitm\\lib\\site-packages\\IPython\\core\\ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1171\u001b[0m ):\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\iitm\\lib\\site-packages\\IPython\\core\\ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\iitm\\lib\\site-packages\\IPython\\core\\ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "from lib import get_openai_embeddings\n",
    "#from lib import \n",
    "import os\n",
    "#from embeddings import load_bert_model,get_bert_embeddings\n",
    "from lib import get_metadata_from_context\n",
    "model = \"bert\"\n",
    "model_path = os.getcwd() + f\"\\\\models_reinitialized\\\\{model}\"\n",
    "tokenizer_path = model_path + \"\\\\tokenizer\\\\\"\n",
    "schema = os.environ[\"DATABASE_SCHEMA\"]\n",
    "table = os.environ[\"DATABASE_TABLE\"]\n",
    "\n",
    "pageno=1\n",
    "option = \"instruction-manual-fisher-et-eat-easy-e-valves-cl125-through-cl600-en-124782.pdf\"\n",
    "\n",
    "extracted_context, table_text = run_gpt4v_image_fisher(option, pageno)\n",
    "#print(extracted_context, table_text)\n",
    "working_directory = os.getcwd() + \"\\\\tempimages\\\\\"\n",
    "FOLDER  = option.replace(\".pdf\",\"\")\n",
    "file_images_directory = f\"{working_directory}\\\\{FOLDER}\"\n",
    "print(file_images_directory)\n",
    "# meta,context = get_metadata_from_context(extracted_context, source=option, pageno=pageno,image_dir=file_images_directory, pdf_name=FOLDER)\n",
    "# print(meta,context)\n",
    "# num_tokens,cost = insert_bert_embeddings_postgresql(meta = meta,context=context,pageno=pageno, schema=schema, table = table, table_text= table_text,model=model,tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempimages\\instruction-manual-fisher-et-eat-easy-e-valves-cl125-through-cl600-en-124782\\instruction-manual-fisher-et-eat-easy-e-valves-cl125-through-cl600-en-124782-page-29.png\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "from PIL import Image\n",
    "full_path = \"C:\\\\Users\\\\Ashish.Madkaikar\\\\OneDrive - Emerson\\\\Source\\\\ai_agents\\\\examples\\\\OS_ChatWithYourDocumentationAgent\\\\tempimages\\\\\\\\instruction-manual-fisher-et-eat-easy-e-valves-cl125-through-cl600-en-124782\\\\instruction-manual-fisher-et-eat-easy-e-valves-cl125-through-cl600-en-124782-page-29.png\"\n",
    "def get_relative_path(full_path):\n",
    "    path = Path(full_path)\n",
    "    \n",
    "    return path.relative_to(path.parent.parent.parent)\n",
    "pa = get_relative_path(full_path)\n",
    "\n",
    "\n",
    "print(str(pa))\n",
    "#img = Image.open(pa)\n",
    "#img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta,context = get_metadata_from_context(extracted_context, source=option, pageno=pageno,image_dir=file_images_directory, pdf_name=FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"] \n",
    "openai.api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"] \n",
    "openai.api_base = os.environ[\"AZURE_OPENAI_ENDPOINT_VISION\"]\n",
    "openai.api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "\n",
    "def summarize_fisher(extracted_context, model=\"gpt-4\"):\n",
    "    '''\n",
    "    returns response to the question asked \n",
    "\n",
    "    extracted_context:\n",
    "    table_text:str , text extrac\n",
    "    questions:list or array of str,  questions to be asked\n",
    "    q:int , question index for asking specific question at the given index  \n",
    "\n",
    "    '''\n",
    "    sys_message = \"'You are an AI assistant capable of processing and summarizing complex documents with diagrams.'\"\n",
    "    user_prompt = f\"Please analyze give text - {extracted_context} ignoring information in tables and provide the information in the following format:\\\\r\\\\n1. Summary: Provide a concise summary of the document, focusing on the main points and overall context.\\\\r\\\\n2. Content: Your task is to extract all information from the document in a detailed and granular manner. Pay special attention to diagrams. Ensure that no information is omitted and no tables are summarized. Avoid summarizing; instead, be explicit with the details. Take your time, as the purpose is to thoroughly record all the information from the document.\\\\r\\\\n3. Category: List key categories or keywords, with a focus on main products or concepts mentioned in the document. Categories should be abstracted and listed, separated by commas, with a maximum of 10 words.\\\\r\\\\nThe purpose is to enable another system to read and understand this information in detail, to facilitate answering precise questions based on the document\\'s context.\\\\r\\\\nPlease return the information in the following format:\\\\r\\\\n\\\\r\\\\n#summary\\\\r\\\\n<summary text>\\\\r\\\\n\\\\r\\\\n#content\\\\r\\\\n<content text>\\\\r\\\\n\\\\r\\\\n#category\\\\r\\\\n[<category 1>, <category 2>, <category 3>, ...]\"\n",
    "     \n",
    "    response = openai.chat.completions.create(\n",
    "                            model=model,\n",
    "                            messages=[\n",
    "                                {\"role\": \"system\", \"content\": sys_message},\n",
    "                                {\"role\": \"user\", \"content\": user_prompt}\n",
    "                            ],\n",
    "                            temperature=0.7,\n",
    "                            max_tokens=1000,\n",
    "                        )\n",
    "    #st.write(response.choices)\n",
    "    #answer = response.choices[0].message.content\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def is_table_normalized(table_text, model=\"gpt-4\"):\n",
    "    #print(table_text)\n",
    "    '''\n",
    "    returns normalized table response to the question asked \n",
    "\n",
    "    extracted_context:\n",
    "    table_text:str , text extrac\n",
    "    questions:list or array of str,  questions to be asked\n",
    "    q:int , question index for asking specific question at the given index  \n",
    "\n",
    "    '''\n",
    "\n",
    "    system_message = \"You are a specialized AI programs that normalizes complex table structures while maintaining the relationships between columns and rows in the table.\"\n",
    "    \n",
    "    prompt = f\"\"\"Analyze the {table_text} and return whether the table is normalized like a matrix and what is your confidence score, lett the answer be very short and brief\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "                            model=model,\n",
    "                            messages=[\n",
    "                                {\"role\": \"system\", \"content\": system_message},\n",
    "                                {\"role\": \"user\", \"content\": prompt}\n",
    "                            ],\n",
    "                            temperature=0.7,\n",
    "                            max_tokens=1000,\n",
    "                        )\n",
    "    #st.write(response.choices)\n",
    "    #answer = response.choices[0].message.content\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def normalize_table(table_text, model=\"gpt-4\"):\n",
    "    #print(table_text)\n",
    "    '''\n",
    "    returns normalized table response to the question asked \n",
    "\n",
    "    extracted_context:\n",
    "    table_text:str , text extrac\n",
    "    questions:list or array of str,  questions to be asked\n",
    "    q:int , question index for asking specific question at the given index  \n",
    "\n",
    "    '''\n",
    "\n",
    "    system_message = \"You are a specialized AI programs that normalizes complex table structures while maintaining the relationships between columns and rows in the table.\"\n",
    "    \n",
    "    prompt = f\"\"\"Normalize the given table : {table_text} and return the normalized table with consistent structure where each row represents a record and each column represents an attribute of that record without any explaination or additional information\"\"\"\n",
    "\n",
    "    # prompt = f\"\"\"Using context: {extracted_context}, find the answer for the following question: {questions[q]} then again verify your answer for question:{questions[q]} using this additional context:{table_text}, after comparing your two answers, without mentionining and explaining how you compared or verified give precise answer without repeatation of information in your answer. \n",
    "    # Please limit your response to the information provided in the context. If there isn't enough information, state that more is needed. To personalize your response, include emoticons.\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "                            model=model,\n",
    "                            messages=[\n",
    "                                {\"role\": \"system\", \"content\": system_message},\n",
    "                                {\"role\": \"user\", \"content\": prompt}\n",
    "                            ],\n",
    "                            temperature=0.7,\n",
    "                            max_tokens=1000,\n",
    "                        )\n",
    "    #st.write(response.choices)\n",
    "    #answer = response.choices[0].message.content\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DESCRIPTION',\n",
       "  'Standard Trim Cage\\nWhisper Trim I Cage\\nCavitrol III - 1 Stage Cage',\n",
       "  'Cavitrol III - 2 Stage Cage\\nWhisper Trim III Cage\\nWhisperFlo Cage'],\n",
       " [None,\n",
       "  '-198 to 593(cid:2)C (-325 to 1100(cid:2)F)',\n",
       "  '-198 to 593(cid:2)C (-325 to 1100(cid:2)F)'],\n",
       " ['Full Capacity Valves', 'Part Number', 'Part Number'],\n",
       " ['NPS 1 and 1‐1/4\\nNPS 1‐1/2 (NPS 2 EAT)\\nNPS 2\\nNPS 2‐1/2 (NPS 3 EAT)\\nNPS 3 (NPS 4 EAT)\\nNPS 4 (NPS 6 EAT)\\nNPS 6\\nNPS 8',\n",
       "  'RGASKETX162\\nRGASKETX172\\nRGASKETX182\\nRGASKETX192\\nRGASKETX202\\nRGASKETX212\\nRGASKETX222\\nRGASKETX232',\n",
       "  'RGASKETX422\\nRGASKETX432\\nRGASKETX442\\nRGASKETX452\\nRGASKETX462\\nRGASKETX472\\nRGASKETX482\\n10A3265X152'],\n",
       " ['Restricted Capacity Valves w/ Metal Seating', '', ''],\n",
       " ['NPS 1‐1/2 x 1 (NPS 2 x 1 EAT)\\nNPS 2 x 1\\nNPS 2‐1/2 x 1‐1/2 (NPS 3 x 1‐1/2 EAT)\\nNPS 3 x 2 (NPS 4 x 2 EAT)\\nNPS 4 x 2‐1/2 (NPS 6 x 2‐1/2 EAT)',\n",
       "  'RGASKETX242\\nRGASKETX252\\nRGASKETX262\\nRGASKETX272\\nRGASKETX282',\n",
       "  '- - -\\n- - -\\n- - -\\n- - -\\n- - -']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from pdfplumber.utils.pdfinternals import resolve_and_decode, resolve\n",
    "from lib import respond_fisher,run_gpt4v_image_fisher\n",
    "import camelot\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#extracted_context, table_text = run_gpt4v_image_fisher(option, pageno)\n",
    "#normalize_table = normalize_table(table)\n",
    "# question = \"What is the gasket kit part number of a 8 inch ET control valve with whisper Trim I?\"\n",
    "# answer = respond_fisher(extracted_context=extracted_context, table_text=table, questions=[question], q=0,model=\"gpt-4\" )\n",
    "# answer\n",
    "# text = page.extract_text(keep_blank_chars=True)\n",
    "# print(text)\n",
    "# flavor = \"lattice\"\n",
    "# text = \"\"\n",
    "# #lines = page.extract_text_lines(layout=False, strip=True, return_chars=True)\n",
    "# display(table)\n",
    "# # for row in table:\n",
    "#     print(row)\n",
    "#pageno=1\n",
    "option = \"instruction-manual-fisher-et-eat-easy-e-valves-cl125-through-cl600-en-124782.pdf\"\n",
    "\n",
    "\n",
    "\n",
    "def extract_tables_pdfplumber(filepath, pageno, table_settings, show_debug, normalize_tables):\n",
    "    tabletext = \"\"\n",
    "    if table_settings == None:\n",
    "        table_settings = {\n",
    "            \"vertical_strategy\": \"lines\", \n",
    "            \"horizontal_strategy\": \"lines\",\n",
    "            \"explicit_vertical_lines\": [],\n",
    "            \"explicit_horizontal_lines\": []\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        pdf = pdfplumber.open(filepath)\n",
    "        page = pdf.pages[pageno]\n",
    "        im = page.to_image()\n",
    "        if show_debug:\n",
    "            im.reset().debug_tablefinder(table_settings)\n",
    "            display(im.debug_tablefinder())\n",
    "        tabletext = page.extract_table(table_settings)\n",
    "    except Exception as e :\n",
    "        print(e)\n",
    "        tabletext = \"Error while parsing PDF, either file is not in right format or not present or pageno doesnot exist\"  \n",
    "    finally:\n",
    "        pdf = \"\"\n",
    "          \n",
    "\n",
    "    return tabletext\n",
    "\n",
    "pageno=25\n",
    "working_directory = os.getcwd() + \"\\\\data\\\\\"\n",
    "#inputfile = \"p2_fds_e431.pdf\"\n",
    "#inputfile = f\"d103428x012.pdf\"\n",
    "#inputfile = f\"fisher_ET__26_Gasket_modified_Table.pdf\"\n",
    "inputfile = f\"instruction-manual-fisher-et-eat-easy-e-valves-cl125-through-cl600-en-124782.pdf\"\n",
    "file = f\"{working_directory}\\\\{inputfile}\"\n",
    "\n",
    "#display(im.debug_tablefinder())\n",
    "table_settings = {\n",
    "    \"vertical_strategy\": \"lines\", \n",
    "    \"horizontal_strategy\": \"lines\",\n",
    "    \"explicit_vertical_lines\": [],\n",
    "    \"explicit_horizontal_lines\": []\n",
    "}\n",
    "table = extract_tables_pdfplumber(file,pageno, table_settings=table_settings, show_debug=False)\n",
    "display(table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalize_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m normalized_table \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_table\u001b[49m(table)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(normalized_table)\n\u001b[0;32m      3\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the gasket kit part number of a 8 inch ET control valve with whisper Trim I?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalize_table' is not defined"
     ]
    }
   ],
   "source": [
    "normalized_table = normalize_table(table)\n",
    "print(normalized_table)\n",
    "question = \"What is the gasket kit part number of a 8 inch ET control valve with whisper Trim I?\"\n",
    "answer = respond_fisher(extracted_context=extracted_context, table_text=normalized_table, questions=[question], q=0,model=\"gpt-4\" )\n",
    "answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table is not normalized like a matrix. Confidence score: High.\n",
      "\n",
      "Normalization issues include:\n",
      "- The first row contains multiple values in a single cell.\n",
      "- The rows represent different sizes but share a structure that is not consistent for the last row (the replacement value '10A3265X152' does not follow the 'RGASKETX4xx' pattern).\n",
      "- The table combines different types of data without separate fields (sizes, part numbers, and temperature ranges).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tb = is_table_normalized(table)\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Standard Designation', 'Common Name or Tradename'],\n",
       " ['CoCr‐A Hardfacing Alloy\\nR30006\\nS17400 SST\\nS31600 SST',\n",
       "  'CoCr‐A\\nAlloy 6 Casting\\n17‐4PH Stainless Steel\\n316 Stainless Steel'],\n",
       " ['S41000 SST\\nS41600 SST\\nWCC Carbon Steel Casting',\n",
       "  '410 Stainless Steel\\n416 Stainless Steel\\nWCC']]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "StructTreeMissing",
     "evalue": "PDF has no structure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStructTreeMissing\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m pageno \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[0;32m      3\u001b[0m page \u001b[38;5;241m=\u001b[39m pdf\u001b[38;5;241m.\u001b[39mpages[pageno]\n\u001b[1;32m----> 4\u001b[0m stree \u001b[38;5;241m=\u001b[39m \u001b[43mPDFStructTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mto_image()\n\u001b[0;32m      6\u001b[0m img\u001b[38;5;241m.\u001b[39mdraw_rects(stree\u001b[38;5;241m.\u001b[39melement_bbox(td) \u001b[38;5;28;01mfor\u001b[39;00m td \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTD\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Ashish.Madkaikar\\Anaconda3\\envs\\torch3.9\\lib\\site-packages\\pdfplumber\\structure.py:80\u001b[0m, in \u001b[0;36mPDFStructTree.__init__\u001b[1;34m(self, doc, page)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdoc\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStructTreeRoot\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc\u001b[38;5;241m.\u001b[39mcatalog:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StructTreeMissing(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDF has no structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m resolve1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc\u001b[38;5;241m.\u001b[39mcatalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStructTreeRoot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrole_map \u001b[38;5;241m=\u001b[39m resolve1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoleMap\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n",
      "\u001b[1;31mStructTreeMissing\u001b[0m: PDF has no structure"
     ]
    }
   ],
   "source": [
    "from pdfplumber.structure import PDFStructTree\n",
    "pageno = 25\n",
    "page = pdf.pages[pageno]\n",
    "stree = PDFStructTree(pdf, page)\n",
    "img = page.to_image()\n",
    "img.draw_rects(stree.element_bbox(td) for td in table.find_all(\"TD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#summary\\nThe document is an instruction manual for Fisher™ ET and EAT easy-e™ Valves, with a focus on models CL125 through CL600. It provides guidelines for installation, maintenance, and parts information specifically for NPS 1 through 8 Fisher ET valves, and NPS 1 through 6 EAT valves with CL600 ratings. The manual emphasizes the necessity of being fully trained and qualified before installing, operating, or maintaining these valves to avoid personal injury or property damage. It includes a list of contents and a cautionary notice, along with a figure depicting the Fisher ET Control Valve with a 667 Actuator.\\n\\n#content\\nThe document outlines the following sections in its contents:\\n- Introduction\\n- Scope of Manual\\n- Description\\n- Specifications\\n- Educational Services\\n- Installation\\n- Maintenance\\n- Packing Lubrication\\n- Packing Maintenance\\n- Replacing Packing\\n- Trim Maintenance\\n- Disassembly\\n- Lapping Metal Seats\\n- Valve Plug Maintenance\\n- Assembly\\n- ENVIRO-SEAL™ Bellows Seal Bonnet\\n- Replacing a Plain or Extension Bonnet with an ENVIRO-SEAL Bellows Seal Bonnet (Stem/Bellows Assembly)\\n- Replacement of an Installed ENVIRO-SEAL Bellows Seal Bonnet (Stem/Bellows Assembly)\\n- Parts Ordering\\n- Purging the ENVIRO-SEAL Bellows Seal Bonnet\\n- Parts Kits\\n- Parts List\\n\\nThe manual also includes a detailed figure, Figure 1, which shows the Fisher ET Control Valve with 667 Actuator. The figure is a diagram of the valve assembly with all its components visibly labeled, but the specific labels are not readable in the provided image.\\n\\nThe manual includes a warning icon indicating that the information within is critical for safe operation and must be followed to prevent injuries or damages. It also directs users to consult separate manuals for instructions on actuators and accessories and to contact the Emerson sales office for any queries regarding the instructions.\\n\\n#category\\n[Fisher ET Valves, EAT easy-e™ Valves, Instruction Manual, Control Valve, Actuator, Safety Precautions, Installation, Maintenance, ENVIRO-SEAL™ Bellows Seal Bonnet, Parts Information]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'                                                                                    0  1\\n                                                                  CL125 through CL600   \\n                                                                             Contents   \\n  Introduction\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1\\n       Scope of Manual\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1\\n   Description\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  3\\n    Specifications\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  3\\n          Educational Services\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . .  3\\nInstallation\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  4\\n   Maintenance\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  5\\n         Packing Lubrication\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .  6\\n             Packing Maintenance\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . .  6\\n                 Replacing Packing\\\\n. . . . . . . . . . . . . . . . . . . . . . . . .  7\\n            Trim Maintenance\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 13                                                                                    0  1       2\\nInstallation\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  4        \\n   Maintenance\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  5        \\n         Packing Lubrication\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .  6        \\n             Packing Maintenance\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . .  6        \\n                 Replacing Packing\\\\n. . . . . . . . . . . . . . . . . . . . . . . . .  7        \\n            Trim Maintenance\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 13        \\n               Disassembly\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13        \\n                   Lapping Metal Seats\\\\n. . . . . . . . . . . . . . . . . . . . . . . 15        \\n                      Valve Plug Maintenance\\\\n. . . . . . . . . . . . . . . . . . . . 16        \\n            Assembly\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18        \\n                          ENVIRO‐SEAL™ Bellows Seal Bonnet\\\\n. . . . . . . . . . . . . 20        \\n                                        Replacing a Plain or Extension Bonnet with an           \\n                                                      ENVIRO‐SEAL Bellows Seal Bonnet           \\n                             (Stem/Bellows Assembly)\\\\n. . . . . . . . . . . . . . . . 20        \\n                                              Replacement of an Installed ENVIRO‐SEAL           \\n                                                                  Bellows Seal Bonnet           \\n                             (Stem/Bellows Assembly)\\\\n. . . . . . . . . . . . . . . . 23        \\n                                       Purging the ENVIRO‐SEAL Bellows Seal Bonnet\\\\n. 25        \\n    Parts Ordering\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25        \\n                                                                                         W1916‐4\\nParts Kits\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26        \\nParts List\\\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31        '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[['VALVE SIZE, NPS', 'STAGE', 'WEIGHT', None],\n",
       " [None, None, 'kg', 'lb'],\n",
       " [None, '2-stage', '63', None],\n",
       " [None, '3-stage', '68', None],\n",
       " [None, '2-stage', '93', None],\n",
       " [None, '3-stage', '105', None],\n",
       " [None, '2-stage', '212', None],\n",
       " [None, '3-stage', '234', None],\n",
       " [None, '3-stage', '518', None]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(extracted_context) \n",
    "display(table_text)\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The available shut off classifications for ET valves with Cavitrol III 1‐stage cage Metal are IV (standard) and V (optional). 😊',\n",
       " 'What are the availabe shut off classifications for ET valves with Cavitrol III 1‐stage cage Metal?')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
